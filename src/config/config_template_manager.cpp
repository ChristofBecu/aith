#include "config_template_manager.h"
#include <stdexcept>
#include <algorithm>
#include <iostream>

ConfigTemplate ConfigTemplateManager::getProviderTemplate(const std::string& provider) {
    const auto& templates = getTemplates();
    std::string normalizedProvider = normalizeProviderName(provider);
    
    auto it = templates.find(normalizedProvider);
    if (it == templates.end()) {
        throw std::invalid_argument("Unsupported provider: " + provider);
    }
    
    return it->second;
}

std::vector<std::string> ConfigTemplateManager::getSupportedProviders() {
    const auto& templates = getTemplates();
    std::vector<std::string> providers;
    
    for (const auto& pair : templates) {
        providers.push_back(pair.first);
    }
    
    return providers;
}

bool ConfigTemplateManager::isKnownProvider(const std::string& provider) {
    const auto& templates = getTemplates();
    std::string normalizedProvider = normalizeProviderName(provider);
    return templates.find(normalizedProvider) != templates.end();
}

std::string ConfigTemplateManager::generateConfigContent(const std::string& provider,
                                                       const std::string& apiKey,
                                                       const std::string& model) {
    std::string content = "# Configuration for " + provider + " provider\n";
    content += "# Generated by AITH Configuration Wizard\n\n";
    
    if (isKnownProvider(provider)) {
        auto config = getProviderTemplate(provider);
        
        content += "# API endpoint URL\n";
        content += "API_URL=" + config.apiUrl + "\n\n";
        
        content += "# Your API key\n";
        content += "API_KEY=" + apiKey + "\n\n";
        
        content += "# Default model to use\n";
        if (!model.empty()) {
            content += "DEFAULT_MODEL=" + model + "\n\n";
        } else {
            content += "DEFAULT_MODEL=" + config.defaultModel + "\n\n";
        }
        
        // Add any additional settings
        if (!config.additionalSettings.empty()) {
            content += "# Additional settings\n";
            for (const auto& setting : config.additionalSettings) {
                content += setting.first + "=" + setting.second + "\n";
            }
            content += "\n";
        }
        
        // Add available models as comments
        if (!config.availableModels.empty()) {
            content += "# Available models for this provider:\n";
            for (const auto& availableModel : config.availableModels) {
                content += "# - " + availableModel + "\n";
            }
        }
    } else {
        // Basic template for unknown providers
        content += "API_URL=\n";
        content += "API_KEY=" + apiKey + "\n";
        if (!model.empty()) {
            content += "DEFAULT_MODEL=" + model + "\n";
        } else {
            content += "DEFAULT_MODEL=\n";
        }
    }
    
    return content;
}

std::string ConfigTemplateManager::getProviderDescription(const std::string& provider) {
    if (!isKnownProvider(provider)) {
        return "Custom provider";
    }
    
    auto config = getProviderTemplate(provider);
    return config.description;
}

void ConfigTemplateManager::displayProviderTemplate(const std::string& provider) {
    if (!isKnownProvider(provider)) {
        std::cout << "No template information available for: " << provider << std::endl;
        return;
    }
    
    auto config = getProviderTemplate(provider);
    
    std::cout << "Provider: " << provider << std::endl;
    std::cout << "Description: " << config.description << std::endl;
    std::cout << "API URL: " << config.apiUrl << std::endl;
    std::cout << "Recommended Model: " << config.defaultModel << std::endl;
    
    if (!config.availableModels.empty()) {
        std::cout << "Available Models:" << std::endl;
        for (const auto& model : config.availableModels) {
            std::cout << "  - " << model << std::endl;
        }
    }
}

std::map<std::string, ConfigTemplate> ConfigTemplateManager::initializeTemplates() {
    std::map<std::string, ConfigTemplate> templates;
    
    // Groq configuration
    templates["groq"] = {
        "https://api.groq.com/openai/v1",
        "llama-3.1-70b-versatile",
        {
            "llama-3.1-70b-versatile",
            "llama-3.1-8b-instant",
            "llama-3.2-90b-text-preview",
            "llama-3.2-11b-text-preview",
            "llama-3.2-3b-preview",
            "llama-3.2-1b-preview",
            "mixtral-8x7b-32768",
            "gemma2-9b-it",
            "gemma-7b-it"
        },
        "Fast inference with Llama and other open models",
        {}
    };
    
    // OpenRouter configuration
    templates["openrouter"] = {
        "https://openrouter.ai/api/v1",
        "meta-llama/llama-3.1-405b-instruct",
        {
            "meta-llama/llama-3.1-405b-instruct",
            "meta-llama/llama-3.1-70b-instruct",
            "meta-llama/llama-3.1-8b-instruct",
            "anthropic/claude-3.5-sonnet",
            "openai/gpt-4o",
            "openai/gpt-4o-mini",
            "google/gemini-pro-1.5",
            "cohere/command-r-plus"
        },
        "Access to multiple AI models through one API",
        {}
    };
    
    // Anthropic configuration
    templates["anthropic"] = {
        "https://api.anthropic.com/v1",
        "claude-3-5-sonnet-20241022",
        {
            "claude-3-5-sonnet-20241022",
            "claude-3-5-haiku-20241022",
            "claude-3-opus-20240229",
            "claude-3-sonnet-20240229",
            "claude-3-haiku-20240307"
        },
        "Claude models by Anthropic",
        {}
    };
    
    // OpenAI configuration
    templates["openai"] = {
        "https://api.openai.com/v1",
        "gpt-4o",
        {
            "gpt-4o",
            "gpt-4o-mini",
            "gpt-4-turbo",
            "gpt-4",
            "gpt-3.5-turbo"
        },
        "OpenAI's GPT models",
        {}
    };
    
    // Together configuration
    templates["together"] = {
        "https://api.together.xyz/v1",
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        {
            "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
            "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
            "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
        },
        "Fast inference for open source models",
        {}
    };
    
    return templates;
}

const std::map<std::string, ConfigTemplate>& ConfigTemplateManager::getTemplates() {
    static auto templates = initializeTemplates();
    return templates;
}

std::string ConfigTemplateManager::normalizeProviderName(const std::string& provider) {
    std::string normalized = provider;
    std::transform(normalized.begin(), normalized.end(), normalized.begin(), ::tolower);
    return normalized;
}
